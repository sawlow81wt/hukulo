{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git push origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from chainer import Chain\n",
    "import chainer.links as L\n",
    "import glob\n",
    "import chainer\n",
    "from chainer import function\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = L.VGG16Layers()\n",
    "convert_image = chainer.links.model.vision.vgg.prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim_matrix(matrix):\n",
    "  d = matrix @ matrix.T\n",
    "  norm = (matrix * matrix).sum(axis=1, keepdims=True) ** .5\n",
    "  return d / norm /norm.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_as_array(path, dtype=np.float32):\n",
    "  f = Image.open(path)\n",
    "  image = np.asarray(f, dtype=dtype)\n",
    "  return convert_image(image)\n",
    "\n",
    "def read_image_as_array_croped(path, dtype=np.float32):\n",
    "  img = utils.read_image(path, color=True)\n",
    "  bboxes, labels, scores = model.predict([img])\n",
    "  #vis_bbox(img, bboxes[0], labels[0], scores[0], label_names=voc_bbox_label_names)\n",
    "  im = Image.open(path)\n",
    "  for bbox, label in zip(bboxes, labels):\n",
    "    bbox = bbox[0][[1,0,3,2]]\n",
    "    crop_img = im.crop(bbox)\n",
    "    return convert_image(np.asarray(crop_img, dtype=dtype))\n",
    "  \n",
    "data_path = glob.glob(\"./data/*\")\n",
    "data = np.asarray([read_image_as_array_croped(path) for path in data_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with function.no_backprop_mode():\n",
    "  h = vgg(data, layers=['fc6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = h['fc6'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(data_path, matrix):\n",
    "  print(i)\n",
    "  print(cos_sim(matrix[6], j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import chainercv\n",
    "from chainercv import utils\n",
    "from chainercv.datasets import voc_bbox_label_names\n",
    "from chainercv.visualizations import vis_bbox\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = chainercv.links.SSD512(n_fg_class=len(voc_bbox_label_names), pretrained_model='voc0712')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in data_path:\n",
    "  img = utils.read_image(path, color=True)\n",
    "  bboxes, labels, scores = model.predict([img])\n",
    "  #vis_bbox(img, bboxes[0], labels[0], scores[0], label_names=voc_bbox_label_names)\n",
    "  im = Image.open(path)\n",
    "  for bbox, label in zip(bboxes, labels):\n",
    "    bbox = bbox[0][[1,0,3,2]]\n",
    "    crop_img = im.crop(bbox)\n",
    "    plt.imshow(np.array(crop_img))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import copy\n",
    "import warnings\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import chainer\n",
    "from chainer.datasets import TransformDataset\n",
    "from chainer.optimizer import WeightDecay\n",
    "from chainer import serializers\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "from chainer.training import triggers\n",
    "from chainer.links.model.vision import resnet\n",
    "\n",
    "import chainercv\n",
    "from chainercv.extensions import DetectionVOCEvaluator\n",
    "from chainercv.links.model.ssd import GradientScaling\n",
    "from chainercv.links.model.ssd import multibox_loss\n",
    "from chainercv import transforms\n",
    "\n",
    "from chainercv.links.model.ssd import random_crop_with_bbox_constraints\n",
    "from chainercv.links.model.ssd import random_distort\n",
    "from chainercv.links.model.ssd import resize_with_random_interpolation\n",
    "\n",
    "\n",
    "from chainercv.links import SSD300\n",
    "from chainercv.links import SSD512\n",
    "from chainercv.utils import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiboxTrainChain(chainer.Chain):\n",
    "\n",
    "    def __init__(self, model, alpha=1, k=3):\n",
    "        super(MultiboxTrainChain, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.model = model\n",
    "        self.alpha = alpha\n",
    "        self.k = k\n",
    "\n",
    "    def __call__(self, imgs, gt_mb_locs, gt_mb_labels):\n",
    "        mb_locs, mb_confs = self.model(imgs)\n",
    "        loc_loss, conf_loss = multibox_loss(\n",
    "            mb_locs, mb_confs, gt_mb_locs, gt_mb_labels, self.k)\n",
    "        loss = loc_loss * self.alpha + conf_loss\n",
    "\n",
    "        chainer.reporter.report(\n",
    "            {'loss': loss, 'loss/loc': loc_loss, 'loss/conf': conf_loss},\n",
    "            self)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform(object):\n",
    "\n",
    "    def __init__(self, coder, size, mean):\n",
    "        # to send cpu, make a copy\n",
    "        self.coder = copy.copy(coder)\n",
    "        self.coder.to_cpu()\n",
    "\n",
    "        self.size = size\n",
    "        self.mean = mean\n",
    "\n",
    "    def __call__(self, in_data):\n",
    "        # There are five data augmentation steps\n",
    "        # 1. Color augmentation\n",
    "        # 2. Random expansion\n",
    "        # 3. Random cropping\n",
    "        # 4. Resizing with random interpolation\n",
    "        # 5. Random horizontal flipping\n",
    "\n",
    "        img, bbox, label = in_data\n",
    "\n",
    "        # 1. Color augmentation\n",
    "        img = random_distort(img)\n",
    "\n",
    "        # 2. Random expansion\n",
    "        if np.random.randint(2):\n",
    "            img, param = transforms.random_expand(\n",
    "                img, fill=self.mean, return_param=True)\n",
    "            bbox = transforms.translate_bbox(\n",
    "                bbox, y_offset=param['y_offset'], x_offset=param['x_offset'])\n",
    "\n",
    "        # 3. Random cropping\n",
    "        img, param = random_crop_with_bbox_constraints(\n",
    "            img, bbox, return_param=True)\n",
    "        bbox, param = transforms.crop_bbox(\n",
    "            bbox, y_slice=param['y_slice'], x_slice=param['x_slice'],\n",
    "            allow_outside_center=False, return_param=True)\n",
    "        label = label[param['index']]\n",
    "\n",
    "        # 4. Resizing with random interpolatation\n",
    "        _, H, W = img.shape\n",
    "        img = resize_with_random_interpolation(img, (self.size, self.size))\n",
    "        bbox = transforms.resize_bbox(bbox, (H, W), (self.size, self.size))\n",
    "\n",
    "        # 5. Random horizontal flipping\n",
    "        img, params = transforms.random_flip(\n",
    "            img, x_random=True, return_param=True)\n",
    "        bbox = transforms.flip_bbox(\n",
    "            bbox, (self.size, self.size), x_flip=params['x_flip'])\n",
    "\n",
    "        # Preparation for SSD network\n",
    "        img -= self.mean\n",
    "        mb_loc, mb_label = self.coder.encode(bbox, label)\n",
    "\n",
    "        return img, mb_loc, mb_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer \n",
    "from pathlib import Path\n",
    "\n",
    "label_names = ('tops', 'bottoms')\n",
    "\n",
    "class BBoxDataset(chainer.dataset.DatasetMixin):\n",
    "  def __init__(self, data_dir='data', split='train'):\n",
    "    id_list_file = os.path.join(\n",
    "      data_dir, 'ImageSets/{0}.txt'.format(split))\n",
    "    self.ids = [id_.strip() for id_ in open(id_list_file)]\n",
    "    self.data_dir = data_dir\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.ids)\n",
    "  \n",
    "  def get_example(self, i):\n",
    "    id_ = self.ids[i]\n",
    "    \n",
    "    json_path = Path('data', 'Annotations', 'annotation.json')\n",
    "    json_loaded = json.load(json_path.open('r'))\n",
    "    \n",
    "    jpg_path = Path('data', 'images', id_ + '.jpg')\n",
    "    jpg_size = jpg_path.stat().st_size\n",
    "    anno = json_loaded[id_ + '.jpg' + str(jpg_size)]\n",
    "\n",
    "    bbox = []\n",
    "    label = []\n",
    "    for obj in anno['regions']:\n",
    "      bndbox_anno = obj['shape_attributes']\n",
    "      bbox.append([\n",
    "        bndbox_anno['y'],\n",
    "        bndbox_anno['x'],\n",
    "        bndbox_anno['y'] + bndbox_anno['height'],\n",
    "        bndbox_anno['x'] + bndbox_anno['width']])\n",
    "      name = obj['region_attributes']['type'].lower().strip()\n",
    "      label.append(label_names.index(name))\n",
    "    bbox = np.stack(bbox).astype(np.float32)\n",
    "    label = np.stack(label).astype(np.int32)\n",
    "    img = read_image(jpg_path.as_posix(), color=True)\n",
    "    return img, bbox, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "\n",
    "def main():\n",
    "  model = SSD300(n_fg_class=len(label_names),\n",
    "    pretrained_model='via_model')  \n",
    "  model.use_preset('evaluate')\n",
    "  train_chain = MultiboxTrainChain(model)\n",
    "  if gpu >= 0:\n",
    "    chainer.cuda.get_device_from_id(gpu).use()\n",
    "    model.to_gpu()\n",
    "\n",
    "  train = TransformDataset(\n",
    "    BBoxDataset(split='train'),\n",
    "    Transform(model.coder, model.insize, model.mean))\n",
    "  train_iter = chainer.iterators.SerialIterator(train, 10)\n",
    "\n",
    "  test = BBoxDataset(split='test')\n",
    "  test_iter = chainer.iterators.SerialIterator(\n",
    "  test, 2, repeat=False, shuffle=False)\n",
    "\n",
    "  optimizer = chainer.optimizers.MomentumSGD(lr=0.0001)\n",
    "  optimizer.setup(train_chain)\n",
    "  for param in train_chain.params():\n",
    "    if param.name == 'b':\n",
    "      param.update_rule.add_hook(GradientScaling(2))\n",
    "    else:\n",
    "      param.update_rule.add_hook(WeightDecay(0.0005))\n",
    "\n",
    "  updater = training.updaters.StandardUpdater(train_iter, optimizer, device=gpu)\n",
    "  trainer = training.Trainer(updater, (1000, 'iteration'), 'result')\n",
    "  trainer.extend(\n",
    "    DetectionVOCEvaluator(\n",
    "    test_iter, model, use_07_metric=True,\n",
    "    label_names=label_names),\n",
    "    trigger=(10, 'iteration'))\n",
    "\n",
    "  log_interval = 10, 'iteration'\n",
    "  trainer.extend(extensions.LogReport(trigger=log_interval))\n",
    "  trainer.extend(extensions.observe_lr(), trigger=log_interval)\n",
    "  trainer.extend(extensions.PrintReport(\n",
    "    ['epoch', 'iteration', 'lr',\n",
    "    'main/loss', 'main/loss/loc', 'main/loss/conf',\n",
    "    'validation/main/map']),\n",
    "    trigger=log_interval)\n",
    "  trainer.extend(extensions.ProgressBar(update_interval=10))\n",
    "  trainer.run()\n",
    "  serializers.save_npz('via_model', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoge = BBoxDataset(split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in hoge[0]:\n",
    "  print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.asarray(hoge[1][0]).transpose(1,2,0) / 255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hoge[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SSD300(n_fg_class=len(label_names),\n",
    "    pretrained_model='via_model')\n",
    "bboxes, labels, scores = model.predict([hoge[1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainercv.visualizations import vis_bbox\n",
    "vis_bbox(hoge[1][0], bboxes[0], labels[0], scores[0], label_names=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import chainercv\n",
    "from chainercv.visualizations import vis_bbox\n",
    "from chainercv import utils\n",
    "from PIL import Image\n",
    "data_path = glob.glob(\"./data/images/*\")\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in data_path[-10:]:\n",
    "  img = utils.read_image(path, color=True)\n",
    "  bboxes, labels, scores = model.predict([img])\n",
    "  #vis_bbox(img, bboxes[0], labels[0], scores[0], label_names=label_names)\n",
    "  im = Image.open(path)\n",
    "  for bbox, label in zip(bboxes, labels):\n",
    "    for b, l in zip(bbox, label):\n",
    "      print(l)\n",
    "      b = b[[1,0,3,2]]\n",
    "      crop_img = im.crop(b)\n",
    "      plt.imshow(np.array(crop_img))\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/Annotations/annotation.json\", mode=\"r\") as f:\n",
    "  json_list = json.load(f)\n",
    "for item in json_list.items():\n",
    "  if item[1]['regions']:\n",
    "    print(item[0].split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "\n",
    "annoy_model = AnnoyIndex(4096)\n",
    "with function.no_backprop_mode():\n",
    "  for i, path in enumerate(data_path):\n",
    "    img = utils.read_image(path, color=True)\n",
    "    bboxes, labels, scores = model.predict([img])\n",
    "    #vis_bbox(img, bboxes[0], labels[0], scores[0], label_names=label_names)\n",
    "    im = Image.open(path)\n",
    "    for bbox, label in zip(bboxes, labels):\n",
    "      for b, l in zip(bbox, label):\n",
    "        if l==0:\n",
    "          b = b[[1,0,3,2]]\n",
    "          crop_img = im.crop(b)\n",
    "          h = vgg(convert_image(np.asarray(crop_img, dtype=np.float32))[np.newaxis,:,:,:], layers=['fc6'])\n",
    "          annoy_model.add_item(i, h['fc6'][0].data)\n",
    "annoy_model.build(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "query_img = utils.read_image(\"data/test/yamatoshi.jpg\", color=True)\n",
    "im = Image.open(\"data/test/yamatoshi.jpg\")\n",
    "bboxes, labels, scores = model.predict([query_img])\n",
    "with function.no_backprop_mode():\n",
    "  for bbox, label in zip(bboxes, labels):\n",
    "    for b, l in zip(bbox, label):\n",
    "      if l==1:\n",
    "        b = b[[1,0,3,2]]\n",
    "        crop_img = im.crop(b)\n",
    "        ax = fig.add_subplot(1, 6, 1)\n",
    "        ax.imshow(np.array(crop_img))\n",
    "        h = vgg(convert_image(np.asarray(crop_img, dtype=np.float32))[np.newaxis,:,:,:], layers=['fc6'])\n",
    "        predict_indexes = annoy_model.get_nns_by_vector(h['fc6'][0].data, 5, search_k=-1)\n",
    "        print(predict_indexes)\n",
    "        \n",
    "for idx, predict_index in enumerate(predict_indexes):\n",
    "  neibor_image = data_path[predict_index]\n",
    "  print(neibor_image)\n",
    "  img = utils.read_image(neibor_image, color=True)\n",
    "  bboxes, labels, scores = model.predict([img])\n",
    "  im = Image.open(neibor_image)\n",
    "  for bbox, label in zip(bboxes, labels):\n",
    "    for b, l in zip(bbox, label):\n",
    "      if l==1:\n",
    "        b = b[[1,0,3,2]]\n",
    "        crop_img = im.crop(b)\n",
    "        ax = fig.add_subplot(1, 6, idx+2)\n",
    "        ax.imshow(np.array(crop_img))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
